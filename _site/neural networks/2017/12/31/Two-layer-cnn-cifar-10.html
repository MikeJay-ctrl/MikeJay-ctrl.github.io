<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>CNN in TensorFlow - CIFAR-10 Classification</title>
  <meta name="description" content="As I’ve spent quite a bit of time demonstrating raw convnets on the MNIST dataset. I thought I’d mix things up quickly and wizz through an implementation of ...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4444/neural%20networks/2017/12/31/Two-layer-cnn-cifar-10.html">
  <link rel="alternate" type="application/rss+xml" title="Mike James - I had a bit of spare time.." href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">Mike James - I had a bit of spare time..</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
            <a class="page-link" href="/about/">About</a>
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">CNN in TensorFlow - CIFAR-10 Classification</h1>
    <p class="post-meta">
      <time datetime="2017-12-31T10:00:24+00:00" itemprop="datePublished">
        
        Dec 31, 2017
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p><br /><br />
As I’ve spent quite a bit of time demonstrating raw convnets on the MNIST dataset. I thought I’d mix things up quickly and wizz through an implementation of a 2 layer convolutional neural network and train it on  the CIFAR-10 dataset.</p>

<p>Details of the CIFAR-10 dataset can be found HERE.</p>

<p>The dataset is based on this paper: <br />
<strong><em>Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009</em></strong></p>

<p>Essentially its a dataset of 60000 32x32 training images in 10 classes, 6000 images per class.
The classes are:</p>

<ul>
  <li>airplane</li>
  <li>automobile</li>
  <li>bird</li>
  <li>cat</li>
  <li>deer</li>
  <li>dog</li>
  <li>frog</li>
  <li>horse</li>
  <li>ship</li>
  <li>truck</li>
</ul>

<p>we’ll now see how simple it is to implement a convolutional neural network in tensorflow.
I’ll also be adding some additional layers to the network in order to help learning to converge quicker as well as improve the accuracy of predictions.</p>

<p><br /><br /></p>
<h1 id="1-import-data">1. Import Data</h1>

<div class="highlighter-rouge"><pre class="highlight"><code>#Import training data
data_all = [None]*2
data = []
labels = []
for i in range(1,6):
    with open("cs231n/datasets/cifar-10-batches-py/data_batch_%d" % i, 'rb') as db:
        data_all = pickle.load(db, encoding='bytes')
        data.extend(data_all[b'data'].reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype("uint8"))
        labels.extend(data_all[b'labels'])

data = np.array(data)
labels = np.array(labels)
print(data.shape) 

#Sanity Check.. Visualise data
for i in range(5):
    image = data[i]
    plt.subplot(1,5,i+1)
    plt.imshow(image)    
</code></pre>
</div>

<p><br />
<img src="/images/img/2017/12/cnn-tf-cifar-1.png" alt="train images" />
<br /><br /></p>

<div class="highlighter-rouge"><pre class="highlight"><code>#import test data
test_data = []
test_labels = []
with open("cs231n/datasets/cifar-10-batches-py/data_batch_%d" % i, 'rb') as db:
    td = pickle.load(db, encoding='latin1')
    test_data.extend(td['data'].reshape(10000, 3, 32, 32).transpose(    0,2,3,1).astype("uint8"))
    test_labels.extend(td['labels'])

#Sanity Check.. Visualise data
for i in range(5):
    image = test_data[i]
    plt.subplot(1,5,i+1)
    plt.imshow(image)
</code></pre>
</div>

<p><br />
<img src="/images/img/2017/12/cnn-tf-cifar-2.png" alt="test images" /></p>

<p>Above I am importing the Training data and test data and visualizing the corrisponding images seporately, this is because the CIFAR-10 dataset comes pre-seporated therefore the user is not required to bulk import and manually partition the data.</p>

<p>The images can be seen below, they are random samples from 5 of the 10 categories. They may appear blury but thats to be expected from 32*32 pixel images!</p>

<p><br /><br /></p>
<h1 id="2-tf-placeholders">2. TF-Placeholders</h1>

<p>In tensorflow you must first define placeholders for any variables you need will be inputting into the graph from the ‘outside world’. Usually this means data and labels.
Im also adding a keep_prob placeholder to allow me to perform Batch Normalization.</p>

<div class="highlighter-rouge"><pre class="highlight"><code># Define and train model
tf.reset_default_graph()

x = tf.placeholder(tf.float32, [None, 32, 32, 3])
y = tf.placeholder(tf.int64, [None])
keep_prob = tf.placeholder(tf.float32)
</code></pre>
</div>

<p><br /><br /></p>
<h1 id="3-tf-variables">3. TF-Variables</h1>
<p>Next you need to create your tensorflow variables which together define the componants that make up the topology of the graph.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>#
# Create TF Variables
#
#Convolution layers
wconv1 = tf.get_variable('wconv1', [5,5, 3, 32])
bconv1 = tf.get_variable('bconv1', [32])

#Add BatchNormalization layer between conv layers
conv_bn_gamma = tf.get_variable('conv_bn_gamma', shape=[32])
conv_bn_beta = tf.get_variable('conv_bn_beta', shape=[32])

wconv2 = tf.get_variable('wconv2', [5,5,32,64])
bconv2 = tf.get_variable('bconv2', [64])


#affine layers
fc_w1 = tf.get_variable('fc_w1', [16*16*64, 100])
fc_b1 = tf.get_variable('fc_b1', [100])

fc_w2 = tf.get_variable('fc_w2', [100, 10])
fc_b2 = tf.get_variable('fc_b2', [10])


#Add BatchNormalization layer between conv layers
fc_bn_gamma = tf.get_variable('fc_bn_gamma', shape=[100])
fc_bn_beta = tf.get_variable('fc_bn_beta', shape=[100])
</code></pre>
</div>

<p><br /><br /></p>
<h1 id="4-topology--optimization">4. Topology &amp; Optimization</h1>
<p><br />
Below we define how the layers interconnect..</p>

<div class="highlighter-rouge"><pre class="highlight"><code>c1_out = tf.nn.conv2d(x, wconv1, strides=[1,1,1,1], padding='SAME') + bconv1
c1_out = tf.nn.relu(c1_out)

mean, var = tf.nn.moments(c1_out, axes=[0,1,2], keep_dims=False)
conv_bn = tf.nn.batch_normalization(c1_out, mean, var, conv_bn_gamma, conv_bn_beta, 1e-6)

c1_pool = tf.layers.max_pooling2d(inputs=conv_bn, pool_size=[2,2], strides=2)  


c2_out = tf.nn.conv2d(c1_pool, wconv2, strides=[1,1,1,1], padding="SAME") + bconv2
c2_out = tf.nn.relu(c2_out)


c2_flat = tf.reshape(c2_out, shape=[-1, (16*16*64)])

fc1_out = tf.matmul(c2_flat, fc_w1) + fc_b1
fc1_out = tf.nn.relu(fc1_out)

mean, var = tf.nn.moments(fc1_out, axes=[0], keep_dims=True)
fc_bn = tf.nn.batch_normalization(fc1_out, mean, var, fc_bn_gamma, fc_bn_beta, 1e-6)


h_fc1_drop = tf.nn.dropout(fc_bn, keep_prob)
logits = tf.matmul(h_fc1_drop, fc_w2) + fc_b2
</code></pre>
</div>

<p><br /><br />
And let tensorflow know how we want to optimise our weights and calculate loss..</p>

<div class="highlighter-rouge"><pre class="highlight"><code>predictions = tf.nn.softmax(logits)
predicted_class = tf.argmax(predictions, axis=1)

total_loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf.one_hot(y, 10), logits=logits)
mean_loss = tf.reduce_mean(total_loss)

optimizer = tf.train.AdamOptimizer(5e-4).minimize(mean_loss)

correct_prediction = tf.equal(predicted_class, y)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
</code></pre>
</div>

<p><br /><br /></p>
<h1 id="5-train">5. Train</h1>
<p>For the final stop on our whistle stop tour we can run create our session and run our graph. I have chosen to run this on a GPU on a google cloud instance reduce computation time.</p>

<div class="highlighter-rouge"><pre class="highlight"><code># Run using GPU
with tf.Session() as sess:
    with tf.device("/gpu:0"):
        sess.run(tf.global_variables_initializer())
        batch_size=400
       
        def train(num_its):  
            for i in range(num_its):
                batch_idx = np.random.randint(data.shape[0], size=batch_size)
                x_batch = data[batch_idx]
                y_batch = labels[batch_idx]
                training_feed_dict ={ x: x_batch, y: y_batch, keep_prob:0.5}
                sess.run(optimizer, training_feed_dict)
            
        train(1000)
        
        test_feed_dict = {x: test_data, y: test_labels, keep_prob:1}
        acc = sess.run(accuracy, feed_dict=test_feed_dict)
        print("test set accuracy is {0:.1%}".format(acc))
</code></pre>
</div>


  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Mike James - I had a bit of spare time..</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              Mike James - I had a bit of spare time..
            
            </li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/MikeJay-ctrl"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">MikeJay-ctrl</span></a>

          </li>
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Im always exploring new areas of Software Engineering and Computer Science. So from now on.. Whenever I have a bit of spare time, ill do a quick post and explore some of the themes here.
Be sure to check back, when you get some time of your own.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
